{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMsmxhE0xCS/+Gb3++wKYQu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swifttech-Consult/Machine_Learning101/blob/main/ML_ASSESSMENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B442l4ZpkjY_"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Anthony Akore : anthony.akore@workwithaya.com\")\n",
        "\n",
        "print(\"ML Assesment Solution\")\n",
        "\n",
        "# Check GPU availability\n",
        "gpu_info = tf.test.gpu_device_name()\n",
        "if gpu_info:\n",
        "    print(\"GPU:\", gpu_info)\n",
        "else:\n",
        "    print(\"No GPU available.\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "# Load dataset from Google Drive with the directory path\n",
        "dataset_dir = \"/content/gdrive/MyDrive/Covid\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# STEP 1\n",
        "# create, allocate and display images datasets with labels\n",
        "\n",
        "\n",
        "#1.1\n",
        "# Create a dataset from the directory\n",
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_dir,\n",
        "    image_size=(224, 224),  # Resize to a consistent size\n",
        "    batch_size=64,\n",
        "    validation_split=0.8,\n",
        "    subset=\"training\",\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "#1.2\n",
        "# Allocate for validation\n",
        "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_dir,\n",
        "    image_size=(224, 224),  # Resize to a consistent size\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "#1.3\n",
        "# Iterate through the test dataset and display images with labels\n",
        "plt.figure(figsize=(20, 20))  # Adjust the figure size\n",
        "for images, labels in dataset.take(1):  # Take one batch of images for display\n",
        "    for i in range(min(len(images), 60)):  # View Limited images\n",
        "        plt.subplot(10, 6, i + 1)  # Create a 10x6grid\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#1.4\n",
        "# Define class names (COVID-19 and Normal)\n",
        "class_names = dataset.class_names\n",
        "\n",
        "#1.5\n",
        "# Initialize lists to store true labels and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#STEP 2\n",
        "# Define , Compile and Train your CNN model\n",
        "\n",
        "\n",
        "#2.1\n",
        "# Define your CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (COVID-19 or not)\n",
        "])\n",
        "\n",
        "#2.2\n",
        "# Define data augmentation in the model\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    data_augmentation,\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "#2.3\n",
        "# Compile your model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#2.4\n",
        "# Train your model and collect accuracy values\n",
        "history = model.fit(dataset, epochs=10, validation_data=validation_dataset)\n",
        "\n",
        "#2.5\n",
        "# Collect true labels and predicted labels during evaluation\n",
        "for images, labels in validation_dataset:\n",
        "    true_labels.extend(labels.numpy())  # Collect true labels\n",
        "    predictions = model.predict(images)  # Predict labels\n",
        "    predicted_labels.extend((predictions > 0.5).astype(int).flatten())  # Convert probabilities to binary labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# STEP 3\n",
        "# Calculate Accuracy, Store values and Visiualized Graph\n",
        "\n",
        "#3.1\n",
        "# Calculate accuracy\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "#3.2\n",
        "# Create lists to store accuracy values\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "\n",
        "#3.3\n",
        "# Store accuracy values in lists\n",
        "train_accuracy.extend(history.history['accuracy'])\n",
        "val_accuracy.extend(history.history['val_accuracy'])\n",
        "\n",
        "#3.4\n",
        "# Add Values and Print Accuracy, Precision, Recall and F1 score\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "#3.5\n",
        "# Plot the accuracy values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_accuracy, label='Training Accuracy')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy Over Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#3.6\n",
        "# Print true labels and predicted labels for each image\n",
        "for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
        "    print(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}